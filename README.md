**-Introduction**  
I performed a comprehensive data preprocessing workflow for this assignment on multiple educational datasets. The key steps included importing and inspecting the datasets, renaming columns for consistency, and merging them based on common identifiers. After cleaning the data by addressing missing values and removing irrelevant entries, I created new columns to calculate the proportions of enrollment based on gender and urban demographics. Finally, I filtered outliers and removed specific school types to ensure data relevance and integrity.  

**-Key documents**  
(1) The result of the cleaned data contains 8200 lines of data and is located in _seda_plus.csv_.   
(2) The _Assn_1_code_lf.py_ contains a step-by-step data preprocessing procedure I used in this assignment.

**-Self-reflections**  
Although I've tried to do data analysis several times in the past few years, this is my first time following a scientific procedure to do data cleaning and preprocessing, so it was a little challenging. For the whole process, I would rank 5/5 for me. At first, I was stuck for about 1.5 hours, emerging four data frames. I still remember that the console showed that I encountered some error called 'MemoryError,' meaning I didn't have enough RAM. I've tried different methods to solve this error, and even though none of these worked, I never gave up searching for the alternative. After countless prompts, I suddenly realized that maybe the table itself went wrong, so I downloaded the tables from the course site again. I FIXED IT; I DID. The reason for this bug is kind of silly because the first time I downloaded the tables, I clicked the button to change some properties, which led to the duplicities of some redundant data and then caused the error. The rest of the steps went smoothly, and they really helped me get to know the Pandas Library a lot more. 
